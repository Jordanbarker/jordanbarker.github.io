{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://aclanthology.org/D14-1181.pdf] Convolutional Neural Networks for Sentence Classification by Yoon Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Headlines: 19200\n",
      "Number of Test Headlines: 4800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 65-Year-Old Man's Typewriter Was &lt;strong&gt;Des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can You Identify These 5 UNITED STATES Leaders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Index of Economic Activity Declined in March\\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015's Best News Bloopers Are Here And They're...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18 Pictures Everyone Who Loves Spilling The Te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  label\n",
       "0  A 65-Year-Old Man's Typewriter Was <strong>Des...      1\n",
       "1  Can You Identify These 5 UNITED STATES Leaders...      1\n",
       "2   Index of Economic Activity Declined in March\\r\\n      0\n",
       "3  2015's Best News Bloopers Are Here And They're...      1\n",
       "4  18 Pictures Everyone Who Loves Spilling The Te...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])\n",
    "\n",
    "print(f'Number of Train Headlines: {len(x_train)}')\n",
    "print(f'Number of Test Headlines: {len(x_test)}')\n",
    "df_train.iloc[:,1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word2vec_vector(w2v_model, sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            index = w2v_model.wv.key_to_index[word]\n",
    "        except KeyError as e:\n",
    "            index = 0\n",
    "        padded_X[i] = index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device)#.view(1, -1)\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "  preprocessed_data = []\n",
    "  for text in data:\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    preprocessed_data.append(tokens)\n",
    "  return preprocessed_data\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, shuffle=True, batch_size=1, num_workers=1):\n",
    "    return DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=shuffle, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=False) # Was throwing errors with True\n",
    "\n",
    "# Train Word2vec model\n",
    "preprocessed_x_train = preprocess(x_train)\n",
    "preprocessed_x_test = preprocess(x_test)\n",
    "w2v_model = Word2Vec(preprocessed_x_train, vector_size=500, min_count=1, workers=3, window=3, sg=1)\n",
    "max_sen_len = max(map(len, preprocessed_x_train))\n",
    "padding_idx = w2v_model.wv.key_to_index['pad']\n",
    "\n",
    "# Make tensor datasets\n",
    "x_train_tensor = torch.stack([make_word2vec_vector(w2v_model, sentence) for sentence in preprocessed_x_train])\n",
    "x_test_tensor = torch.stack([make_word2vec_vector(w2v_model, sentence) for sentence in preprocessed_x_test])\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validate_size = int(0.2 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, validate_size])\n",
    "train_dl = create_dataloader(train_dataset)\n",
    "val_dl = create_dataloader(val_dataset, shuffle=False)\n",
    "test_dl = create_dataloader(TensorDataset(x_test_tensor, y_test_tensor), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCNClassifier(pl.LightningModule):\n",
    "    def __init__(self, w2vmodel, num_classes=2, window_sizes=(1,2,3,5)):\n",
    "        super().__init__()\n",
    "        self.lr = 0.0005\n",
    "        self.num_classes = num_classes\n",
    "        weights = w2vmodel.wv # used to initialize the embedding layer\n",
    "        EMBEDDING_SIZE = 500  # Use this to set the embedding_dim in embedding layer\n",
    "        NUM_FILTERS = 10      # Number of filters in CNN\n",
    "\n",
    "        weights = []\n",
    "        for key in w2vmodel.wv.index_to_key:\n",
    "            weights.append(w2vmodel.wv.get_vector('to'))\n",
    "        weights = torch.FloatTensor(weights)\n",
    "        self.emb = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "        conv_list = []\n",
    "        for window in window_sizes:\n",
    "            conv_list.append(nn.Conv2d(1, NUM_FILTERS, (window, EMBEDDING_SIZE), padding=(window - 1, 0)))\n",
    "        self.convs = nn.ModuleList(conv_list)\n",
    "        \n",
    "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = [F.tanh(conv(x).squeeze(2)) for conv in self.convs]  \n",
    "        x = [F.max_pool1d(i, i.size(1)) for i in x] \n",
    "        x = torch.cat(x).squeeze(1)\n",
    "        logits = self.fc(x)\n",
    "        probs = F.softmax(logits, dim=0)\n",
    "        # return logits\n",
    "        return probs.unsqueeze(0)\n",
    "\n",
    "    def _common_step(self, batch, type):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # print(\"logits shape: \", logits.shape)\n",
    "        # print(\"labels shape: \", y.squeeze().shape)\n",
    "        loss = nn.CrossEntropyLoss()(logits, y)\n",
    "        acc = accuracy(torch.argmax(logits, dim=1), \n",
    "                        y,\n",
    "                        task='multiclass',\n",
    "                        num_classes=self.num_classes)\n",
    "        self.log(f'{type}_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(f'{type}_accuracy', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"validation\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=0.0001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | emb   | Embedding  | 8.5 M \n",
      "1 | convs | ModuleList | 55.0 K\n",
      "2 | fc    | Linear     | 82    \n",
      "-------------------------------------\n",
      "55.1 K    Trainable params\n",
      "8.5 M     Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.418    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5461b3396d4307a6c5ed97aaa50beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865130f7f38f4a53a215b8b37de62c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6428fa8f28794deeb12d730898c01044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6f476b7ec34de5827904425868f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56778835bc914ff4a04df324824ac762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a77a8eac774e3b83c6e571fb4f1a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce97316b69b4aabacdd2c0ee806ffcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "model = CCNClassifier(w2vmodel) \n",
    "model_name = 'CCNClassifier'\n",
    "max_epochs = 5\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# print(\"print wd \", os.getcwd())\n",
    "torch.manual_seed(42) \n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "print(\"Using device: %s\" % device)\n",
    "\n",
    "\n",
    "# wandb.init(project='RF-Fingerprinting')\n",
    "# wandb_logger = WandbLogger(name=f\"{model_name}\", save_dir=f\"../Data/Logs/{model_name}\")\n",
    "# csv_logger = CSVLogger(save_dir=f\"../Data/Logs/{model_name}\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    # logger=[wandb_logger, csv_logger],\n",
    "    # enable_checkpointing=False\n",
    "    # log_every_n_steps=10000\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\eric_\\Documents\\Code\\py_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8322a8a91b44218370f94ec6f68414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.50020831823349      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.813026487827301     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.50020831823349     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.813026487827301    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.813026487827301, 'test_accuracy': 0.50020831823349}]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\eric_\\Documents\\Code\\py_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0c68a18eb54db6a05d6bb5128cbb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49791666865348816    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8153160810470581     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49791666865348816   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8153160810470581    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8153160810470581, 'test_accuracy': 0.49791666865348816}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | emb   | Embedding  | 8.5 M \n",
      "1 | convs | ModuleList | 55.0 K\n",
      "2 | fc    | Linear     | 82    \n",
      "-------------------------------------\n",
      "55.1 K    Trainable params\n",
      "8.5 M     Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.418    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ffbdce91dc4cf88847a7ec2dbf0401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f700f0e95c4746a8a6c34b9a07c077a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1eef067e93418f8ad951fe7c541533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "class CCNClassifier(pl.LightningModule):\n",
    "    def __init__(self, w2vmodel, num_classes=2, cnn_filters=10, window_sizes=(1,2,3,5), emb_size=500):\n",
    "        super().__init__()\n",
    "        self.lr = 0.0005\n",
    "        self.num_classes = num_classes\n",
    "        weights = torch.FloatTensor([w2vmodel.wv.get_vector(key) for key in w2vmodel.wv.index_to_key])\n",
    "        self.emb = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "        conv_list = [nn.Conv2d(1, cnn_filters, (window, emb_size), padding=(window - 1, 0)) for window in window_sizes]\n",
    "        self.convs = nn.ModuleList(conv_list)\n",
    "        \n",
    "        self.fc = nn.Linear(cnn_filters * len(window_sizes), self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = [F.tanh(conv(x).squeeze(2)) for conv in self.convs]  \n",
    "        x = [F.max_pool1d(i, i.size(1)) for i in x] \n",
    "        x = torch.cat(x).squeeze(1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "        # probs = F.softmax(logits, dim=0)\n",
    "        # return probs.unsqueeze(0)\n",
    "\n",
    "    def _common_step(self, batch, type):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # print(\"logits shape: \", logits.shape)\n",
    "        # print(\"x shape\", x.shape)\n",
    "        # print(\"y shape\", y.shape)\n",
    "        # print(\"logits\", logits)\n",
    "        # print(\"y\", y)\n",
    "        # print(\"labels shape: \", y.squeeze().shape)\n",
    "        loss = nn.CrossEntropyLoss()(logits, y.squeeze())\n",
    "        acc = accuracy(torch.argmax(logits).view(-1), \n",
    "                        y,\n",
    "                        task='binary',\n",
    "                        num_classes=self.num_classes)\n",
    "        self.log(f'{type}_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(f'{type}_accuracy', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"validation\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=0.0001)\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "model = CCNClassifier(w2vmodel)\n",
    "max_epochs = 1\n",
    "trainer = pl.Trainer(max_epochs=max_epochs)\n",
    "trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95059ba4be4c49519df8f6ec0f107dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.50020831823349      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7622038125991821     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.50020831823349     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7622038125991821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7622038125991821, 'test_accuracy': 0.50020831823349}]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "window_sizes = (1,2,3,5)\n",
    "num_classes = 2\n",
    "cnn_filters = 10\n",
    "emb_size = 500\n",
    "weights = torch.FloatTensor(np.array([w2vmodel.wv.get_vector(key) for key in w2vmodel.wv.index_to_key]))\n",
    "emb = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "conv_list = [nn.Conv2d(1, cnn_filters, (window, emb_size), padding=(window - 1, 0)) for window in window_sizes]\n",
    "convs = nn.ModuleList(conv_list)\n",
    "fc = nn.Linear(cnn_filters * len(window_sizes), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, shuffle=True, batch_size=32, num_workers=1):\n",
    "    return DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=shuffle, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=False) # Was throwing errors with True\n",
    "\n",
    "dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_dl = create_dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 22]), torch.Size([32]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x.shape, y.shape # (torch.Size([1, 22]), torch.Size([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 22]), torch.Size([1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 500])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = self(x)\n",
    "# print(\"logits shape: \", logits.shape)\n",
    "# print(\"x shape\", x.shape)\n",
    "# print(\"y shape\", y.shape)\n",
    "# print(\"logits\", logits)\n",
    "# print(\"y\", y)\n",
    "# print(\"labels shape: \", y.squeeze().shape)\n",
    "loss = nn.CrossEntropyLoss()(logits, y.squeeze())\n",
    "acc = accuracy(torch.argmax(logits).view(-1), \n",
    "                y,\n",
    "                task='binary',\n",
    "                num_classes=self.num_classes)\n",
    "self.log(f'{type}_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "self.log(f'{type}_accuracy', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 156, 6381,    0,   76,  487, 1284, 1627,    2,   78, 3766, 3766, 3766,\n",
       "          3766, 3766, 3766, 3766, 3766, 3766, 3766, 3766, 3766, 3766]]),\n",
       " tensor([0])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = self.\n",
    "x = [F.tanh(conv(x).squeeze(2)) for conv in self.convs]  \n",
    "x = [F.max_pool1d(i, i.size(1)) for i in x] \n",
    "x = torch.cat(x).squeeze(1)\n",
    "logits = self.fc(x)\n",
    "return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12618816,  0.12382559,  0.2715929 , ..., -0.0252528 ,\n",
       "        -0.03258467, -0.0512457 ],\n",
       "       [ 0.04130232,  0.03092547,  0.03194333, ...,  0.11940952,\n",
       "        -0.08433206,  0.0188638 ],\n",
       "       [ 0.2184581 ,  0.11401746,  0.25613508, ..., -0.0413998 ,\n",
       "        -0.13421682, -0.00919781],\n",
       "       ...,\n",
       "       [ 0.00786052,  0.00455297,  0.00892375, ..., -0.00130982,\n",
       "        -0.00713709,  0.00149295],\n",
       "       [ 0.01807955,  0.0137573 ,  0.02255729, ...,  0.00122181,\n",
       "        -0.01906485, -0.0035723 ],\n",
       "       [ 0.01621657,  0.01486751,  0.02367726, ..., -0.0023468 ,\n",
       "        -0.01647809, -0.0009782 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
