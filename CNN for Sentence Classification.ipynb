{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://aclanthology.org/D14-1181.pdf] Convolutional Neural Networks for Sentence Classification by Yoon Kim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A 65-Year-Old Man's Typewriter Was &lt;strong&gt;Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Can You Identify These 5 UNITED STATES Leaders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Index of Economic Activity Declined in March\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015's Best News Bloopers Are Here And They're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18 Pictures Everyone Who Loves Spilling The Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           headline\n",
       "0      1  A 65-Year-Old Man's Typewriter Was <strong>Des...\n",
       "1      1  Can You Identify These 5 UNITED STATES Leaders...\n",
       "2      0   Index of Economic Activity Declined in March\\r\\n\n",
       "3      1  2015's Best News Bloopers Are Here And They're...\n",
       "4      1  18 Pictures Everyone Who Loves Spilling The Te..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Headlines: 19200\n",
      "Number of Test Headlines: 4800\n",
      "\n",
      "\n",
      "Sample Label and Headlines:\n",
      "1: 27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\n",
      "\n",
      "1: 22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\n",
      "\n",
      "0: PepsiCo Profit Falls 43 Percent\n",
      "\n",
      "0: Website of Bill O'Reilly, FOX News commentator, hacked in retribution\n",
      "\n",
      "1: The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\n",
      "\n",
      "\n",
      "Output of Sample Headlines without Print Statement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\\r\\n',\n",
       " \"22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\\r\\n\",\n",
       " 'PepsiCo Profit Falls 43 Percent\\r\\n',\n",
       " \"Website of Bill O'Reilly, FOX News commentator, hacked in retribution\\r\\n\",\n",
       " 'The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\\r\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])\n",
    "\n",
    "print(f'Number of Train Headlines: {len(x_train)}')\n",
    "print(f'Number of Test Headlines: {len(x_test)}')\n",
    "\n",
    "df_train[['label','headline']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Articles: 1600\n",
      "Number of Test Articles: 400\n",
      "\n",
      "Label Key: {0: 'CS', 1: 'ECE', 2: 'Civil', 3: 'Medical'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A hardware accelerator is presented to compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>An automatized procedure for the parameterizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A review and comparative analyses of methods f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A parallel time integration method for nonline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A redundant system of collocated geodetic sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            article\n",
       "0      1  A hardware accelerator is presented to compute...\n",
       "1      0  An automatized procedure for the parameterizat...\n",
       "2      0  A review and comparative analyses of methods f...\n",
       "3      0  A parallel time integration method for nonline...\n",
       "4      4  A redundant system of collocated geodetic sens..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wos = pd.read_csv('./data/train_wos.csv')\n",
    "df_test_wos = pd.read_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])\n",
    "\n",
    "# Numerical label to domain mapping\n",
    "wos_label = {0:'CS', 1:'ECE', 2:'Civil', 3:'Medical'}\n",
    "# Numerical label to Numerical mapping\n",
    "label_mapping = {0:0, 1:1, 4:2, 5:3}\n",
    "\n",
    "for i, label in enumerate(y_train_wos):\n",
    "    y_train_wos[i] = label_mapping[label]\n",
    "for i, label in enumerate(y_test_wos):\n",
    "    y_test_wos[i] = label_mapping[label]\n",
    "\n",
    "print(f'Number of Train Articles: {len(x_train_wos)}')\n",
    "print(f'Number of Test Articles: {len(x_test_wos)}')\n",
    "\n",
    "print('\\nLabel Key:', wos_label)\n",
    "\n",
    "df_train_wos[['label','article']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "  preprocessed_data = []\n",
    "  for text in data:\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    preprocessed_data.append(tokens)\n",
    "  return preprocessed_data\n",
    "\n",
    "preprocessed_x_train = preprocess(x_train)\n",
    "preprocessed_x_train_wos = preprocess(x_train_wos)\n",
    "\n",
    "preprocessed_x_test = preprocess(x_test)\n",
    "preprocessed_x_test_wos = preprocess(x_test_wos)\n",
    "\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(data, padding=True, sg=1, min_count=1, vector_size=500, workers=3, window=3):\n",
    "    data.append(['pad'])\n",
    "    w2v_model = Word2Vec(data, min_count = min_count, vector_size = vector_size, workers = workers, window = window, sg = sg)\n",
    "    return w2v_model\n",
    "\n",
    "def make_word2vec_vector(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            index = w2vmodel.wv.key_to_index[word]\n",
    "        except KeyError as e:\n",
    "            index = 0\n",
    "        padded_X[i] = index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def make_target(label):\n",
    "  return torch.tensor([label], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train, padding=True, sg=sg, min_count=min_count, vector_size=size, workers=workers, window=window)\n",
    "max_sen_len = max(map(len, preprocessed_x_train))\n",
    "padding_idx = w2vmodel.wv.key_to_index['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCNClassifier(pl.LightningModule):\n",
    "    def __init__(self, w2vmodel, num_classes, window_sizes=(1,2,3,5)):\n",
    "        super().__init__()\n",
    "        weights = w2vmodel.wv # used to initialize the embedding layer\n",
    "        EMBEDDING_SIZE = 500  # Use this to set the embedding_dim in embedding layer\n",
    "        NUM_FILTERS = 10      # Number of filters in CNN\n",
    "\n",
    "        weights = []\n",
    "        for key in w2vmodel.wv.index_to_key:\n",
    "            weights.append(w2vmodel.wv.get_vector('to'))\n",
    "        weights = torch.FloatTensor(weights)\n",
    "        self.emb = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "        conv_list = []\n",
    "        for window in window_sizes:\n",
    "            conv_list.append(nn.Conv2d(1, NUM_FILTERS, (window, EMBEDDING_SIZE), padding=(window - 1, 0)))\n",
    "        self.convs = nn.ModuleList(conv_list)\n",
    "        \n",
    "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = [F.tanh(conv(x).squeeze(2)) for conv in self.convs]  \n",
    "        x = [F.max_pool1d(i, i.size(1)) for i in x] \n",
    "        x = torch.cat(x).squeeze(1)\n",
    "        logits = self.fc(x)\n",
    "        probs = F.softmax(logits, dim=0)\n",
    "        return probs.unsqueeze(0)\n",
    "\n",
    "    def _common_step(self, batch, type):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(logits, y.squeeze())\n",
    "        acc = accuracy(torch.argmax(logits, dim=1), \n",
    "                        y.squeeze(),\n",
    "                        task='multiclass',\n",
    "                        num_classes=self.num_classes)\n",
    "        self.log(f'{type}_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(f'{type}_accuracy', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"validation\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=0.0001)\n",
    "        return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
