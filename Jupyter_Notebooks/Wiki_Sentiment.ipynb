{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81a9b99aa844186b65269daa56374e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abe79cc639e44a6a75465dee65cf161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236384ad4103466b8ed07c8a1f60ff2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8676dc896b49c5a17d2fb286100f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "# https://huggingface.co/datasets/wikimedia/wikipedia/tree/main/20231101.en\n",
    "# https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")\n",
    "sentiment_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# print(dataset)\n",
    "# print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Decode bytes to string if not already done\n",
    "    # if isinstance(text, bytes):\n",
    "        # text = text.decode('utf-8')\n",
    "\n",
    "    # Replace en-dash and similar characters with a standard hyphen\n",
    "    text = re.sub(r'\\xe2\\x80\\x93', '-', text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers except for hyphens, semicolons, and periods\n",
    "    text = re.sub(r'[^\\w\\s\\.-:]', '', text)\n",
    "\n",
    "    # Replace newline characters with space\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "\n",
    "    # Additional normalization like removing extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_into_chunks(text, chunk_size=512, overlap=0):\n",
    "    # Split text into chunks of `chunk_size` with `overlap`\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size - overlap)]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def aggregate_sentiment_results(results):\n",
    "    total_score = 0\n",
    "    count = len(results)\n",
    "    for result in results:\n",
    "        score = result['score']\n",
    "        if result['label'] == 'NEGATIVE':\n",
    "            score = -score\n",
    "        total_score += score\n",
    "    average_score = total_score / count if count > 0 else 0\n",
    "    normalized_score = (average_score + 1) / 2\n",
    "    # overall_sentiment = \"POSITIVE\" if average_score > 0 else \"NEGATIVE\"\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Anarchism: 0.5569816405853528\n",
      "1 - Albedo: 0.18363157163063687\n",
      "2 - A: 0.14465936869382856\n",
      "3 - Alabama: 0.46126076959123546\n",
      "4 - Achilles: 0.5124129707163031\n",
      "5 - Abraham Lincoln: 0.49221770835749673\n"
     ]
    }
   ],
   "source": [
    "# normalize_text(dataset['train'][0]['text'])\n",
    "\n",
    "# features: ['id', 'url', 'title', 'text'],\n",
    "# num_rows: 6407814\n",
    "for index, example in enumerate(dataset['train']):\n",
    "    if index>5:\n",
    "        break\n",
    "    title = example['title']\n",
    "    text = example['text']\n",
    "    normalized_text = normalize_text(text) # np.array(text)\n",
    "    text_chunks = split_into_chunks(normalized_text)\n",
    "    sentiment_results = sentiment_pipeline(text_chunks)\n",
    "    # sentiment_results = analyze_sentiment(text_chunks)\n",
    "    sentiment = aggregate_sentiment_results(sentiment_results)\n",
    "    print(f\"{index} - {title}: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - HM Prison Hull: 0.3094\n",
      "100 - Bicyclus pavonis: 0.0808\n",
      "200 - Ace of Clubs (musical): 0.5303\n",
      "300 - Virginia Caine: 0.8726\n",
      "400 - Baca Kurti: 0.8325\n",
      "500 - Rashid, Iran: 0.2148\n",
      "600 - Dumont Public Schools: 0.7518\n",
      "700 - Dhaka-15: 0.9377\n",
      "800 - Florida Film Critics Circle Awards 2009: 0.8775\n",
      "900 - List of most expensive Indian artists: 0.6931\n",
      "1000 - Harald Hellström: 0.7237\n",
      "1100 - Der Islam: 0.9036\n",
      "1200 - Sewage pumping: 0.0233\n",
      "1300 - Pommel: 0.0581\n",
      "1400 - Farzana Kochai: 0.9856\n",
      "1500 - Ruby (ship): 0.0245\n",
      "1600 - Stare Wądołki: 0.9422\n",
      "1700 - Masao Ono: 0.6755\n",
      "1800 - Bangana zhui: 0.9352\n",
      "1900 - Fédération des femmes du Québec: 0.867\n",
      "2000 - Temple of Augustus and Livia: 0.4007\n",
      "2100 - Live Oak Public Libraries: 0.6776\n",
      "2200 - Langjökull: 0.5409\n",
      "2300 - Galów: 0.9669\n",
      "2400 - Albert Lévy (photographer): 0.9163\n",
      "2500 - Nelson Riddle discography: 0.9943\n",
      "2600 - Remigio Nannini: 0.428\n",
      "2700 - Damon Beesley: 0.9934\n",
      "2800 - Arthur Lyon Fremantle: 0.5363\n",
      "2900 - Bata (village): 0.7766\n",
      "3000 - Mascouche line: 0.2131\n",
      "3100 - Newhard: 0.9839\n",
      "3200 - Maloideae: 0.034\n",
      "3300 - 36th Golden Rooster Awards: 0.9989\n",
      "3400 - Marlene Warfield: 0.9824\n",
      "3500 - Johann Gottfried Berger: 0.4031\n",
      "3600 - Nan Wood Honeyman: 0.5166\n",
      "3700 - 1905 Colorado Agricultural Aggies football team: 0.1438\n",
      "3800 - Sonic's Ultimate Genesis Collection: 0.6449\n",
      "3900 - Victor-Lucien-Sulpice Lécot: 0.7259\n",
      "4000 - 2021 UEC European Track Championships – Men's 1 km time trial: 0.9953\n",
      "4100 - Worlds Apart: 0.7044\n",
      "4200 - Herschel Bennett: 0.2156\n",
      "4300 - 2012 European Weightlifting Championships – Women's 48 kg: 0.942\n",
      "4400 - Megalaemyia elsae: 0.0434\n",
      "4500 - Parakrama Pandyan II: 0.4684\n",
      "4600 - Oba, Alanya: 0.9659\n",
      "4700 - Multitran: 0.1188\n",
      "4800 - Helen M. McLoraine: 0.9638\n",
      "4900 - Labicymbium otti: 0.8089\n",
      "5000 - SA Fillies Classic: 0.5923\n",
      "5100 - Hội Yến Diêu Trì: 0.7465\n",
      "5200 - Dzhelepsko: 0.8537\n",
      "5300 - Mary Ashford: 0.1151\n",
      "5400 - Gogoplata: 0.0233\n",
      "5500 - Exile on Main St. (Supernatural): 0.4853\n",
      "5600 - Big Chicken: 0.2627\n",
      "5700 - Born to Sing (1942 film): 0.3339\n",
      "5800 - Hallelujah (EP): 0.8761\n",
      "5900 - Margaret Bicknell: 0.4928\n",
      "6000 - Pedro Solbes: 0.5933\n",
      "6100 - Odds or Evens: 0.9845\n",
      "6200 - 2015 Rostelecom Cup: 0.6669\n",
      "6300 - Karakocalı, Sungurlu: 0.914\n",
      "6400 - Louis de Pointe du Lac: 0.5903\n",
      "6500 - Hassan Qraytim: 0.9576\n",
      "6600 - Bill's Diner: 0.4369\n",
      "6700 - WVN: 0.004\n",
      "6800 - Papiamento: 0.3765\n",
      "6900 - Alternative flatworm mitochondrial code: 0.2485\n",
      "7000 - Jacob Marley: 0.3487\n",
      "7100 - 1728 map of Copenhagen: 0.0686\n",
      "7200 - Zaranna: 0.9654\n",
      "7300 - Saints Catherine and Florian Church, Gołąb: 0.7986\n",
      "7400 - Morocco women's national football team: 0.6834\n",
      "7500 - Athletics at the 1959 Pan American Games – Men's 10,000 metres: 0.9892\n",
      "7600 - Statue of Alexander von Humboldt (Bläser): 0.9983\n",
      "7700 - Matt Chessé: 0.8001\n",
      "7800 - Freight company: 0.4483\n",
      "7900 - Oliver Frey: 0.6968\n",
      "8000 - Harrison, Lincoln County, Wisconsin: 0.4034\n",
      "8100 - HMS Egeria (1873): 0.3799\n",
      "8200 - Zack Moss: 0.8015\n",
      "8300 - Anochetus nietneri: 0.0886\n",
      "8400 - Central neurogenic hyperventilation: 0.0429\n",
      "8500 - Dirty (2020 film): 0.6853\n",
      "8600 - Clarke County, Alabama: 0.2824\n",
      "8700 - Shuriken Sentai Ninninger: 0.6193\n",
      "8800 - Vestavia Hills High School: 0.5463\n",
      "8900 - Keinänen: 0.9777\n",
      "9000 - Haringhuizen: 0.47\n",
      "9100 - Parapercis hexophtalma: 0.0492\n",
      "9200 - 2018 European Women's Handball Championship: 0.5712\n",
      "9300 - Covenant Life Church: 0.4343\n",
      "9400 - Thermal conductivity detector: 0.3726\n",
      "9500 - Marko Markov: 0.9782\n",
      "9600 - O. Normann Sand: 0.9762\n",
      "9700 - Bulimulus pallidus: 0.0034\n",
      "9800 - Favre-Leuba: 0.9153\n",
      "9900 - Paul Elvinger: 0.9971\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame with specified columns\n",
    "df = pd.DataFrame(columns=['Title', 'Sentiment', 'URL'])\n",
    "\n",
    "subset = dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
    "\n",
    "for index, example in enumerate(subset):\n",
    "\n",
    "    df_size = len(df)\n",
    "    if df_size==10000:\n",
    "        break\n",
    "\n",
    "    title = example['title']\n",
    "    text = example['text']\n",
    "    normalized_text = normalize_text(text)  # np.array(text)\n",
    "    text_chunks = split_into_chunks(normalized_text)\n",
    "    sentiment_results = sentiment_pipeline(text_chunks)\n",
    "    sentiment = aggregate_sentiment_results(sentiment_results)\n",
    "    # sentiment = normalized_score if overall_sentiment==\"POSITIVE\" else -1*normalized_score # \"NEGATIVE\"\n",
    "    sentiment = np.round(sentiment, 4)\n",
    "    # df = df.append({'Title': title, 'Sentiment': sentiment}, ignore_index=True)\n",
    "    df.loc[index] = [title, sentiment, example['url']]\n",
    "    if df_size % 100 == 0 :\n",
    "        print(f\"{df_size} - {title}: {sentiment}\")\n",
    "\n",
    "    # print(f\"{title}: Overall Sentiment: {overall_sentiment}, Score: {sentiment}\")\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df = df.sort_values(\"Sentiment\", ascending=False)\n",
    "df.to_csv('../data/sentiment_analysis_results.csv', index=False)\n",
    "print(\"Saved to file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6407814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.492"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(sentiment,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are approximately 408843 prime numbers between 0 and 6407814\n"
     ]
    }
   ],
   "source": [
    "dataset_length = 6407814\n",
    "primes = int(dataset_length / np.log(dataset_length))\n",
    "print(f\"There are approximately {primes} prime numbers between 0 and {dataset_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
