{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing\n",
    "\n",
    "## Overview\n",
    "\n",
    "### The GIL (Global Interpreter Lock) in Python\n",
    "Python's GIL allows only one thread to execute at a time in a single process, affecting CPU-bound threading performance.\n",
    "\n",
    "### CPU-bound vs. I/O-bound Tasks\n",
    "- CPU-bound tasks: Require significant CPU resources (e.g., mathematical computations).\n",
    "- I/O-bound tasks: Spend time waiting for input/output operations (e.g., reading files, network requests).\n",
    "\n",
    "### Parallelism vs. Concurrency\n",
    "- Parallelism: Performing multiple tasks simultaneously.\n",
    "- Concurrency: Managing multiple tasks at the same time but not necessarily simultaneously.\n",
    "\n",
    "### Challenges\n",
    "- Data Race: Two threads access shared data simultaneously, causing inconsistent results.\n",
    "- Deadlock: Two or more threads wait indefinitely for resources held by each other.\n",
    "- Thread Safety: Writing code that functions correctly during simultaneous execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Parallel Processing with `joblib`\n",
    "\n",
    "`joblib` provides a simple interface for efficient parallel computing.\n",
    "\n",
    "\n",
    "`Parallel(n_jobs=-1)` will automatically distribute the workload across all available CPU cores.\n",
    "\n",
    "Here is a basic example, where we need to call `time_intensive_method()` several times. Doing this in parallel streamlines it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "def time_intensive_method(n):\n",
    "    time.sleep(5)\n",
    "    return n\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(time_intensive_method)(n) for n in range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing with `multiprocessing`\n",
    "```{note}:\n",
    "Special considerations apply when using Jupyter or Windows for this. Check out  \n",
    "[Bob Swinkels's blog on the topic](https://bobswinkels.com/posts/multiprocessing-python-windows-jupyter/) for details.\n",
    "```\n",
    "Creating Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def worker(num):\n",
    "    print(f'Worker {num}')\n",
    "\n",
    "processes = []\n",
    "for i in range(5):\n",
    "    p = Process(target=worker, args=(i,))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "    \n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process, Pool, and `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# worker.py\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "with Pool(4) as pool:\n",
    "    result = pool.map(square, [1, 2, 3, 4])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication Between Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(q):\n",
    "    q.put('Hello from worker')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())  # Output: Hello from worker\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronizing Processes\n",
    "Locks, Semaphores, Events, and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Lock\n",
    "\n",
    "def printer(item, lock):\n",
    "    with lock:\n",
    "        print(item)\n",
    "\n",
    "lock = Lock()\n",
    "items = ['A', 'B', 'C']\n",
    "for item in items:\n",
    "    Process(target=printer, args=(item, lock)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Shared Memory\n",
    "Value and Array in Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def increment(value):\n",
    "    value.value += 1\n",
    "\n",
    "num = Value('i', 0)\n",
    "p = Process(target=increment, args=(num,))\n",
    "p.start()\n",
    "p.join()\n",
    "print(num.value)  # Output: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async\n",
    "Async programming allows for concurrent code execution using coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# async def say_hello():\n",
    "#     print('Hello')\n",
    "#     await asyncio.sleep(1)\n",
    "#     print('World')\n",
    "\n",
    "# asyncio.run(say_hello())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import aiohttp\n",
    "\n",
    "# async def fetch(session, url):\n",
    "#     async with session.get(url) as response:\n",
    "#         return await response.text()\n",
    "\n",
    "# async def main():\n",
    "#     async with aiohttp.ClientSession() as session:\n",
    "#         html = await fetch(session, 'https://example.com')\n",
    "#         print(html)\n",
    "\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Topics\n",
    "- Swifter: Parallel Data Processing with Pandas [(Github page)](https://github.com/jmcarpenter2/swifter)\n",
    "- Dask enables parallel computing with task scheduling and can handle datasets larger than memory.\n",
    "- Numba and CuPy for GPU parallel processing "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
